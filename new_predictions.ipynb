{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New sample prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provide an example of end-to-end pipeline for new and real-time predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "<!-- - [New sample prediction](#New-sample-prediction) -->\n",
    "- [Init](#Init)\n",
    "- [Download Fits](#Download-Fits)\n",
    "- [Preprocessing and downsampling](#Preprocessing-and-downsampling)\n",
    "  - [Instrument correction and exposure normalisation](#Instrument-correction-and-exposure-normalisation)\n",
    "  - [Scaling and downsampling](#Scaling-and-downsampling)\n",
    "- [ROI Crops](#ROI-Crops)\n",
    "- [Predictions](#Predictions)\n",
    "- [Viz](#Viz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm \n",
    "import os\n",
    "import requests\n",
    "\n",
    "# import astropy.time\n",
    "import astropy.units as u\n",
    "import sunpy\n",
    "# from sunpy.net import Fido\n",
    "# from sunpy.net import attrs as a\n",
    "\n",
    "# from aiapy.calibrate import degradation\n",
    "from aiapy.calibrate.util import get_correction_table\n",
    "from aiapy.calibrate import correct_degradation\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from sunpy.coordinates import frames\n",
    "from sunpy.physics.differential_rotation import solar_rotate_coordinate\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "NRT              = True                                   # use near-real-time images (for the fits downloading)\n",
    "sample_date      = pd.to_datetime(\"2024-10-08 23:57:00\")\n",
    "POS_ARCSEC_START = {'13848X1': (32, 112)}   # the ROI id is arbitrary, (x,y) is the ROI center HPC position at (sample_date - 10H)\n",
    "wavelengths      = ['0193', '0211', '0094'] # wavelength used in input\n",
    "folder           = f'/Users/greg/Google Drive/Mi unidad/Projects/Forecast/Results/V2V/new_samples'\n",
    "\n",
    "DOWNLOAD_FITS = True\n",
    "CORRECT_FITS  = True\n",
    "PROCESS_PNG   = True\n",
    "PROCESS_CROPS = True\n",
    "NUM_SIMUS     = 20\n",
    "machine       = 'loc'\n",
    "\n",
    "cadence_minutes = 120\n",
    "\n",
    "start_date = sample_date - datetime.timedelta(hours= 10)\n",
    "end_date   = sample_date + datetime.timedelta(hours= 12)\n",
    "\n",
    "date_range = pd.date_range(start = start_date,\n",
    "                           end   = end_date,\n",
    "                           freq  = datetime.timedelta(seconds=60*cadence_minutes)\n",
    "                           )\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "  os.makedirs(folder, exist_ok=True)\n",
    "  \n",
    "if machine == 'COLAB':\n",
    "  from pathlib import Path\n",
    "  if not Path('/content/drive').exists():\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "  folder = f'/content/drive/MyDrive/Projects/Forecast/Results/V2V/new_samples'\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:06<00:00,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "if DOWNLOAD_FITS:\n",
    "  for current_date in tqdm(date_range):\n",
    "      #if current_date > datetime.datetime(2018, 11, 12, 0, 0, 0):\n",
    "      year = current_date.year\n",
    "      month = current_date.month\n",
    "      day = current_date.day\n",
    "      hour = current_date.hour\n",
    "      minute = current_date.minute\n",
    "\n",
    "      for wavelength in wavelengths:\n",
    "          #if log.loc[current_date,wavelength] == 0 or log.loc[current_date,wavelength] == -1:\n",
    "          if NRT:\n",
    "            url = f'http://jsoc.stanford.edu/data/aia/synoptic/nrt/{year}/{month:02d}/{day:02d}/H{hour:02d}00/AIA{year}{month:02d}{day:02d}_{hour:02d}{minute:02d}00_{wavelength}.fits'\n",
    "          else:\n",
    "            url = f'http://jsoc.stanford.edu/data/aia/synoptic/{year}/{month:02d}/{day:02d}/H{hour:02d}00/AIA{year}{month:02d}{day:02d}_{hour:02d}{minute:02d}_{wavelength}.fits'\n",
    "          # Download the image\n",
    "          \n",
    "          path = f'{folder}/fits/aia'\n",
    "          for subfolder in [f'{year}',f'{month:02d}',f'{day:02d}']:\n",
    "              path = f'{path}/{subfolder}'\n",
    "              if not os.path.exists(path):\n",
    "                  os.makedirs(path, exist_ok = True)\n",
    "          filename = f'{path}/{year}{month:02d}{day:02d}_{hour:02d}{minute:02d}_{wavelength}.fits'\n",
    "          \n",
    "          if not os.path.exists(filename):\n",
    "            response = requests.get(url)\n",
    "        \n",
    "            if response.status_code == 200:\n",
    "                # Save the image to a file\n",
    "                try:\n",
    "                    \n",
    "                    with open(filename, 'wb') as f:\n",
    "                        f.write(response.content)\n",
    "                    # log.loc[current_date,wavelength] = 1\n",
    "                    # log.to_csv(fn_log)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    # log.loc[current_date,wavelength] = -1\n",
    "                  # log.to_csv(fn_log)\n",
    "            else:\n",
    "              print(response.status_code, ' : ', response.reason)\n",
    "              print(url)\n",
    "                # log.loc[current_date,wavelength] = -response.status_code\n",
    "                # log.to_csv(fn_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument correction and exposure normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]WARNING: VerifyWarning: Invalid 'BLANK' keyword in header.  The 'BLANK' keyword is only applicable to integer data, and will be ignored in this HDU. [astropy.io.fits.hdu.image]\n",
      "2024-10-11 01:43:32 - astropy - WARNING: VerifyWarning: Invalid 'BLANK' keyword in header.  The 'BLANK' keyword is only applicable to integer data, and will be ignored in this HDU.\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing sources :  0.0\n",
      "Errors dest     :  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if CORRECT_FITS:\n",
    "  ctMissingSource = 0\n",
    "  ctErr = 0\n",
    "  table = get_correction_table()\n",
    "  for current_date in tqdm(date_range):\n",
    "      year = current_date.year\n",
    "      month = current_date.month\n",
    "      day = current_date.day\n",
    "      hour = current_date.hour\n",
    "      minute = current_date.minute\n",
    "\n",
    "      for wavelength in wavelengths:\n",
    "          path_src  = f'{folder}/fits/aia'\n",
    "          path_dest = f'{folder}/fits/aia_corr'\n",
    "          for subfolder in [f'{year}',f'{month:02d}',f'{day:02d}']:\n",
    "              path_src = f'{path_src}/{subfolder}'\n",
    "          fn_src  = f'{path_src}/{year}{month:02d}{day:02d}_{hour:02d}{minute:02d}_{wavelength}.fits'\n",
    "          if os.path.exists(fn_src):\n",
    "              for subfolder in [f'{year}',f'{month:02d}',f'{day:02d}']:\n",
    "                  path_dest = f'{path_dest}/{subfolder}'\n",
    "              os.makedirs(path_dest, exist_ok=True)\n",
    "              fn_dest = f'{path_dest}/{year}{month:02d}{day:02d}_{hour:02d}{minute:02d}_{wavelength}.fits'\n",
    "              if not os.path.exists(fn_dest):\n",
    "                  try:\n",
    "                      img = sunpy.map.Map(fn_src)\n",
    "                      img = correct_degradation(img, correction_table = table)\n",
    "                      img._data = img.data.astype('float32')\n",
    "                      img._data = img.data / float(img.meta['exptime']) # img = normalize_exposure(img)\n",
    "                      img.save(fn_dest)\n",
    "                  except Exception as e:\n",
    "                      print(current_date)\n",
    "                      print(wavelength)\n",
    "                      print(e)\n",
    "                      ctErr+=1\n",
    "                      # log_jpeg.loc[current_date,wavelength] = -2\n",
    "                          \n",
    "          else:\n",
    "              print('WARNING , no : ', fn_src)\n",
    "              ctMissingSource += 1\n",
    "  #             log_jpeg.loc[current_date,wavelength] = -1\n",
    "  # log_jpeg.to_csv(fn_log_jpeg)\n",
    "  print('Missing sources : ', ctMissingSource/len(wavelengths))\n",
    "  print('Errors dest     : ', ctErr/len(wavelengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SATURATION VALUES : \n",
      "0193 81139.19094000038\n",
      "0211 8179.276461000085\n",
      "0094 6099.484649600037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-08 13:57:00 0193 291.4839 412.0286 -1.0143008 9364.596\n",
      "2024-10-08 13:57:00 0211 136.08289 207.21364 -0.8569284 5496.607\n",
      "2024-10-08 13:57:00 0094 1.3100001 2.598818 -0.45325023 221.11455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:02<00:00,  4.81it/s]\n"
     ]
    }
   ],
   "source": [
    "if PROCESS_PNG:\n",
    "  dim = 1024 # if 1024 no downsampling performed\n",
    "  stats = {}\n",
    "  test_spit_date = datetime.datetime(2020,1,1) # end of datasset  date to compute percentile saturation values\n",
    "  saturation_pctl = 99.9\n",
    "  saturation = {}\n",
    "  stats = {}\n",
    "  thd_std = {}\n",
    "  print('SATURATION VALUES : ')\n",
    "  for w in wavelengths:\n",
    "    # file with images pixel statistics for the whole time-period used in training\n",
    "    fn_stat = f'/Users/greg/Google Drive/Mi unidad/Projects/Forecast/Datasets/Meta/stats_aia_corr_{w}.csv'\n",
    "    stats[w] = pd.read_csv(fn_stat)\n",
    "    stats[w]['timestamp'] = stats[w]['timestamp'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d %H:%M:%S')) # '%Y/%m/%d/H%H00/\n",
    "    stats[w] = stats[w].set_index(['timestamp'])\n",
    "    stats[w] = stats[w].sort_index()\n",
    "    stats[w] = stats[w][stats[w] .index < test_spit_date]\n",
    "    maxs = stats[w]['max']\n",
    "    # maxs = maxs[~np.isnan(maxs)]\n",
    "    saturation[w] = np.nanpercentile(maxs, saturation_pctl)\n",
    "    print(w, saturation[w])#, thd_std[w], avg_std, std_std)\n",
    "    # stats[w].describe()\n",
    "\n",
    "  for current_date in tqdm(date_range):\n",
    "      year = current_date.year\n",
    "      month = current_date.month\n",
    "      day = current_date.day\n",
    "      hour = current_date.hour\n",
    "      minute = current_date.minute\n",
    "      \n",
    "      for wavelength in wavelengths:\n",
    "          path_src  = f'{folder}/fits/aia_corr'\n",
    "          \n",
    "          path_dest = f'{folder}/png/{dim}/{wavelength}'\n",
    "          if not Path(path_dest).exists():\n",
    "            # os.mkdir(path_dest)\n",
    "            os.makedirs(path_dest, exist_ok=True)\n",
    "          \n",
    "          # if log_jpeg.loc[current_date,wavelength] < 1:\n",
    "          for subfolder in [f'{year}',f'{month:02d}',f'{day:02d}']:\n",
    "              path_src = f'{path_src}/{subfolder}'\n",
    "          fn_src  = f'{path_src}/{year}{month:02d}{day:02d}_{hour:02d}{minute:02d}_{wavelength}.fits'\n",
    "          if not os.path.exists(fn_src):\n",
    "              print('WARNIN  : missing , ',fn_src)\n",
    "          else:\n",
    "              for subfolder in [f'{year}',f'{month:02d}',f'{day:02d}']:\n",
    "                  path_dest = f'{path_dest}/{subfolder}'\n",
    "                  if not os.path.exists(path_dest):\n",
    "                      os.mkdir(path_dest)\n",
    "              fn_dest = f'{path_dest}/{year}{month:02d}{day:02d}_{hour:02d}{minute:02d}_{wavelength}.png'\n",
    "              if not Path(fn_dest).exists():\n",
    "                try:\n",
    "                    \n",
    "                    img = sunpy.map.Map(fn_src)\n",
    "                    \n",
    "                    if dim != 1024:\n",
    "                      img = Image.fromarray(img.data)\n",
    "                      img = img.resize((dim,dim),resample = Image.BILINEAR)#LANCZOS)\n",
    "                      img = np.array(img)\n",
    "                    else:\n",
    "                      img = img.data\n",
    "                      \n",
    "                      print(current_date, wavelength, img.mean(), img.std(),  img.min(), img.max() )\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(-2, e)\n",
    "                    continue\n",
    "                try:\n",
    "                    sat = saturation[wavelength]\n",
    "                    img[img<0] = 0\n",
    "                    img[img>sat] = sat\n",
    "                    img = np.log(1+img)\n",
    "                    img = 255 * img / np.log(1+sat)\n",
    "                    img = np.round(img)\n",
    "                    img[img>255]=255 # 256 values\n",
    "                    img = img.astype('uint8')\n",
    "                except Exception as e:\n",
    "                    print(-3, e)\n",
    "                    continue\n",
    "                try:\n",
    "                    img = Image.fromarray(img)\n",
    "                    img.save(fn_dest)\n",
    "                except Exception as e:\n",
    "                    print(-4, e)\n",
    "                    continue  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]WARNING: SunpyUserWarning: Using 'time' assumes an Earth-based observer. [sunpy.physics.differential_rotation]\n",
      "2024-10-11 01:57:19 - sunpy - WARNING: SunpyUserWarning: Using 'time' assumes an Earth-based observer.\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\n"
     ]
    }
   ],
   "source": [
    "if PROCESS_CROPS:\n",
    "  \n",
    "  # dimensions from source\n",
    "  resolution = 2.4 # (arcsec/pix)\n",
    "  dimPatches = 256\n",
    "  # downsampling\n",
    "  downsize   = 128\n",
    "  \n",
    "  path_dest = f'{folder}/ar'\n",
    "  samples_df_path = f'{path_dest}/samples.csv'\n",
    "  path_src = f'{folder}/png/1024'\n",
    "  os.makedirs(path_dest, exist_ok=True)\n",
    "  \n",
    "  # TO DO : optimise the loop on date to open each fd im onlly once\n",
    "  for arnum in tqdm(POS_ARCSEC_START.keys()):\n",
    "    start_pos_hpc = POS_ARCSEC_START[arnum]\n",
    "    hpc_coords = {date_range[0]:SkyCoord(start_pos_hpc[0] * u.arcsec, start_pos_hpc[1] * u.arcsec, obstime=date_range[0], observer='earth',frame=frames.Helioprojective)}\n",
    "    hpc_coords.update({t : solar_rotate_coordinate(hpc_coords[date_range[0]], time=t) for t in date_range[1:]})\n",
    "\n",
    "    sample = pd.DataFrame({'id' : [str(arnum)+'_'+ str(sample_date)], \n",
    "                           'HARPNUM' : [arnum], \n",
    "                           'T' : [sample_date], \n",
    "                           'label' : [arnum[-2:]]},index=[0])\n",
    "    if not os.path.exists(samples_df_path):\n",
    "      sample.to_csv(samples_df_path, index = False)\n",
    "    else:\n",
    "      samples = pd.read_csv(samples_df_path)\n",
    "      if sample.loc[0,'id'] not in  samples['id'].values:\n",
    "        samples = pd.concat([samples,sample],ignore_index=True, axis=0)\n",
    "        samples.to_csv(samples_df_path, index = False)\n",
    "    \n",
    "    for timestamp in hpc_coords.keys():\n",
    "      \n",
    "      \n",
    "    \n",
    "      center_hpc_x = hpc_coords[timestamp].Tx.value\n",
    "      center_hpc_y = hpc_coords[timestamp].Ty.value\n",
    "      \n",
    "      year = timestamp.year\n",
    "      month = timestamp.month\n",
    "      day = timestamp.day\n",
    "      hour = timestamp.hour\n",
    "      minute = timestamp.minute\n",
    "      \n",
    "      fn_srcs  = [f'{path_src}/{wavelength}/{year}/{month:02d}/{day:02d}/{year}{month:02d}{day:02d}_{hour:02d}{minute:02d}_{wavelength}.png' for wavelength in wavelengths]\n",
    "      \n",
    "      for fn_src in fn_srcs:\n",
    "        if not os.path.exists(fn_src):\n",
    "          print('WARNING  : missing , ', fn_src)\n",
    "          \n",
    "      arfolder = f'{path_dest}/{reduce(lambda x,y:x+\"x\"+y, wavelengths)}/{arnum}'\n",
    "      os.makedirs(arfolder, exist_ok=True)\n",
    "      \n",
    "      fn_dest = f'{arfolder}/{arnum}_{year}{month:02d}{day:02d}_{hour:02d}{minute:02d}_{reduce(lambda x,y:x+\"x\"+y, wavelengths)}.png'\n",
    "      \n",
    "      if not os.path.exists(fn_dest):\n",
    "      \n",
    "        full_disk =  Image.merge('RGB',[Image.open(fn_src) for fn_src in fn_srcs])\n",
    "        \n",
    "        imW, imH = full_disk.size\n",
    "        \n",
    "        width = dimPatches # row['width_arcsec_Avg'] / resolution    \n",
    "        height = dimPatches # row['width_arcsec_Avg'] / resolution\n",
    "        \n",
    "        cX = int(np.round(center_hpc_x / resolution + imW/2))\n",
    "        cY = int(np.round(center_hpc_y / resolution + imH/2))\n",
    "        \n",
    "        left = int(np.round(cX - width/2))\n",
    "        right = int(np.round(cX + width/2))\n",
    "        top = int(np.round(cY - height/2))\n",
    "        bottom = int(np.round(cY + height/2))\n",
    "        \n",
    "        ar = full_disk.crop((left, top, right, bottom))\n",
    "        if downsize is not None:\n",
    "          ar = ar.resize((downsize,downsize),resample = Image.BILINEAR)\n",
    "        ar.save(fn_dest)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>HARPNUM</th>\n",
       "      <th>T</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13842X9_2024-10-03 10:21:00</td>\n",
       "      <td>13842X9</td>\n",
       "      <td>2024-10-03 10:21:00</td>\n",
       "      <td>X9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13842X9_2024-10-03 10:24:00</td>\n",
       "      <td>13842X9</td>\n",
       "      <td>2024-10-03 10:24:00</td>\n",
       "      <td>X9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13848X1_2024-10-08 23:57:00</td>\n",
       "      <td>13848X1</td>\n",
       "      <td>2024-10-08 23:57:00</td>\n",
       "      <td>X1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  HARPNUM                    T label\n",
       "0  13842X9_2024-10-03 10:21:00  13842X9  2024-10-03 10:21:00    X9\n",
       "1  13842X9_2024-10-03 10:24:00  13842X9  2024-10-03 10:24:00    X9\n",
       "2  13848X1_2024-10-08 23:57:00  13848X1  2024-10-08 23:57:00    X1"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_ars = f'{folder}/ar'\n",
    "samples_df_path = f'{path_ars}/samples.csv'\n",
    "samples = pd.read_csv(samples_df_path)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_SIMUS is not None:\n",
    "  from diffusion import Diffusion_cond\n",
    "  from module import PaletteModelVideo\n",
    "  from dataloaders import PairedVideosDataset\n",
    "  from torch.utils.data import DataLoader\n",
    "  import copy\n",
    "  import gc\n",
    "  from torch.cuda.amp import autocast\n",
    "  import torch\n",
    "  \n",
    "  MIXED_PREC = True\n",
    "  \n",
    "  pred_sample = samples.iloc[-1:]\n",
    "  \n",
    "  proj_folder = f'/content/drive/MyDrive/Projects/Forecast/Results/V2V/corona_v2v_128_2halfD'\n",
    "  ema_model_path = f\"{proj_folder}/models/ema_best.pt\"\n",
    "  model_tag = ema_model_path.split('/')[-2] + '_' + ema_model_path.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "  \n",
    "  PRED_FOLDER = f'{folder}/preds'\n",
    "  os.makedirs(PRED_FOLDER, exists_ok=True)\n",
    "  \n",
    "  ds = PairedVideosDataset(\n",
    "      dataframe            = pred_sample,\n",
    "      root_dir             = path_ars,\n",
    "      time_interval_min    = 120,\n",
    "      num_frames           = 6,\n",
    "      wavelength           = '0193x0211x0094',\n",
    "      target_channel_index = 2,\n",
    "      real_time            = False\n",
    "  )\n",
    "  loader = DataLoader(\n",
    "    ds, \n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,# pin_memory set to True\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    "  )\n",
    "  device = 'cuda'\n",
    "  model =  PaletteModelVideo(\n",
    "      c_in=4,\n",
    "      c_out=1,\n",
    "      image_size=128,\n",
    "      time_dim=256,\n",
    "      device=device,\n",
    "      latent=False,\n",
    "      frames = 6,\n",
    "      bottleneck_3D = False,\n",
    "      small = True,\n",
    "      extra_att = False\n",
    "  ).to(device)\n",
    "  diffusion = Diffusion_cond(img_size=128, device=device, img_channel=1, num_frames=6)\n",
    "  model = copy.deepcopy(model).eval().requires_grad_(False)\n",
    "  model_checkpoint = torch.load(ema_model_path)\n",
    "  model.load_state_dict(model_checkpoint['model_state'])\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for sim_index in tqdm(range(NUM_SIMUS)):\n",
    "      print('\\n Starting simu : ',sim_index)\n",
    "      for i, (video_input, video_target, label, time) in enumerate(tqdm(loader)):\n",
    "          torch.cuda.empty_cache()\n",
    "          gc.collect()\n",
    "          sampled_images = None\n",
    "          torch.cuda.empty_cache()\n",
    "          gc.collect()\n",
    "          \n",
    "          input = video_input.to(device).float()\n",
    "          target = video_target.to(device).float()\n",
    "          # label = label[0]\n",
    "          # time = time[0]\n",
    "          id = time[0]\n",
    "          arnum = [t.split('_')[0] for t in id]\n",
    "          time = [pd.to_datetime(t.split('_')[-1]).strftime('%Y_%m_%d_%H%M') for t in time]\n",
    "          pred_path = f\"{PRED_FOLDER}/{arnum[0]}/{label[0]}_{arnum[0]}_{time[0]}_sim_{sim_index:03}.npy\"\n",
    "          \n",
    "          if not os.path.exists(pred_path):\n",
    "            if MIXED_PREC:\n",
    "              with autocast():\n",
    "                sampled_images = diffusion.sample(model, y=input, labels=None)\n",
    "            else:\n",
    "              sampled_images = diffusion.sample(model, y=input, labels=None)\n",
    "            sample = sampled_images[0]\n",
    "            sample = ds.Normalisation.reverse_transform_exctracted_chanel(sample.cpu()).permute(1, 2, 3, 0).cpu().numpy()\n",
    "            sample = np.clip((255*sample), 0, 255).astype('uint8')\n",
    "            pred_path = f\"{PRED_FOLDER}/{arnum[0]}\"\n",
    "            if not os.path.exists(pred_path):\n",
    "              os.makedirs(pred_path)\n",
    "            pred_path = f\"{pred_path}/{label[0]}_{arnum[0]}_{time[0]}_sim_{sim_index:03}.npy\"\n",
    "            # if not os.path.exists(pred_path):\n",
    "            np.save(pred_path, sample)\n",
    "            \n",
    "          if sim_index == 0:\n",
    "            pred_input = f\"{PRED_FOLDER}/{arnum[0]}/{label[0]}_{arnum[0]}_{time[0]}_input.npy\"\n",
    "            pred_target = f\"{PRED_FOLDER}/{arnum[0]}/{label[0]}_{arnum[0]}_{time[0]}_target.npy\"\n",
    "            if not os.path.exists(pred_target):\n",
    "              # input = input[:,2:3]\n",
    "              sample = input[0,2:3]\n",
    "              sample = ds.Normalisation.reverse_transform_exctracted_chanel(sample.cpu()).permute(1, 2, 3, 0).cpu().numpy()\n",
    "              sample = np.clip((255*sample), 0, 255).astype('uint8')\n",
    "              pred_input = f\"{PRED_FOLDER}/{arnum[0]}\"\n",
    "              if not os.path.exists(pred_input):\n",
    "                os.makedirs(pred_input)\n",
    "              pred_input = f\"{pred_input}/{label[0]}_{arnum[0]}_{time[0]}_input.npy\"\n",
    "              # if not os.path.exists(pred_input):\n",
    "              np.save(pred_input, sample)\n",
    "              sample = target[0]\n",
    "              sample = ds.Normalisation.reverse_transform_exctracted_chanel(sample.cpu()).permute(1, 2, 3, 0).cpu().numpy()\n",
    "              sample = np.clip((255*sample), 0, 255).astype('uint8')\n",
    "              pred_target = f\"{PRED_FOLDER}/{arnum[0]}\"\n",
    "              if not os.path.exists(pred_target):\n",
    "                os.makedirs(pred_target)\n",
    "              pred_target = f\"{pred_target}/{label[0]}_{arnum[0]}_{time[0]}_target.npy\"\n",
    "              # if not os.path.exists(pred_target):\n",
    "              np.save(pred_target, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>HARPNUM</th>\n",
       "      <th>T</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13842X9_2024-10-03 10:21:00</td>\n",
       "      <td>13842X9</td>\n",
       "      <td>2024-10-03 10:21:00</td>\n",
       "      <td>X9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13842X9_2024-10-03 10:24:00</td>\n",
       "      <td>13842X9</td>\n",
       "      <td>2024-10-03 10:24:00</td>\n",
       "      <td>X9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13848X1_2024-10-08 23:57:00</td>\n",
       "      <td>13848X1</td>\n",
       "      <td>2024-10-08 23:57:00</td>\n",
       "      <td>X1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  HARPNUM                    T label\n",
       "0  13842X9_2024-10-03 10:21:00  13842X9  2024-10-03 10:21:00    X9\n",
       "1  13842X9_2024-10-03 10:24:00  13842X9  2024-10-03 10:24:00    X9\n",
       "2  13848X1_2024-10-08 23:57:00  13848X1  2024-10-08 23:57:00    X1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_ars = f'{folder}/ar'\n",
    "samples_df_path = f'{path_ars}/samples.csv'\n",
    "samples = pd.read_csv(samples_df_path)\n",
    "samples\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAKE_GIFS = True\n",
    "\n",
    "if MAKE_GIFS:\n",
    "  descale = False\n",
    "  sample = samples.iloc[-1]\n",
    "  model_tag = 'ema_best'\n",
    "  pred_paths = f\"{folder}/preds/{sample['HARPNUM']}/{model_tag}\"\n",
    "  label = sample['label']\n",
    "  id = sample['HARPNUM']+'_'+pd.to_datetime(sample['T']).strftime('%Y_%m_%d_%H%M')\n",
    "  \n",
    "  import matplotlib.pyplot as plt\n",
    "  import matplotlib.animation as animation\n",
    "  from glob import glob\n",
    "  def descaling(scaled_image, max = 6099):\n",
    "    max = np.log(1+max)\n",
    "    image = np.exp(max * scaled_image / 255) - 1\n",
    "    return image\n",
    "  def save_and_plot_v2v(video_input, video_target, video_prediction, save_path, title=\"\", fps=4, target_channel = 2,\n",
    "                        vmin = None,\n",
    "                        vmax = None\n",
    "                        ):\n",
    "    \"\"\"\n",
    "    Creates and saves an animation showing three videos side by side.\n",
    "\n",
    "    Args:\n",
    "        input: Numpy array for the true input video of shape (frames, height, width, channels)\n",
    "        video_target: Numpy array for the ground truth of shape (frames, height, width, channels)\n",
    "        ema_samp: Numpy array for the EMA sampled video of shape (frames, height, width, channels)\n",
    "        save_path: Where to save the video (GIF)\n",
    "        title: Optional title for the entire video.\n",
    "        fps: Frames per second for the output video.\n",
    "    \"\"\"\n",
    "    if target_channel:\n",
    "      video_input = video_input[:,:,:,target_channel:target_channel+1]\n",
    "    # Number of frames\n",
    "    frames = video_input.shape[0]\n",
    "    images = []\n",
    "\n",
    "    # Create a figure with three subplots\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "    # Set the initial frame in all subplots\n",
    "    im1 = ax1.imshow(video_input[0], origin='lower', vmin=vmin, vmax=vmax)\n",
    "    ax1.set_title('12 previous hours')\n",
    "\n",
    "    im2 = ax2.imshow(video_target[0], origin='lower', vmin=vmin, vmax=vmax)\n",
    "    ax2.set_title('True next 12h')\n",
    "\n",
    "    im3 = ax3.imshow(video_prediction[0], origin='lower', vmin=vmin, vmax=vmax)\n",
    "    ax3.set_title('Predicted next 12h')\n",
    "\n",
    "    # Add a big title in the middle of all subplots\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    def update(frame_idx):\n",
    "        \"\"\"Updates the plot for the given frame index.\"\"\"\n",
    "        im1.set_array(video_input[frame_idx])\n",
    "        im2.set_array(video_target[frame_idx])\n",
    "        im3.set_array(video_prediction[frame_idx])\n",
    "        return [im1, im2, im3]\n",
    "\n",
    "    def update_gif(frame_idx):\n",
    "      # Convert the canvas to a PIL image and add it to the list\n",
    "      im1.set_array(video_input[frame_idx])\n",
    "      im2.set_array(video_target[frame_idx])\n",
    "      im3.set_array(video_prediction[frame_idx])\n",
    "      fig.canvas.draw()\n",
    "      img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "      img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "      images.append(Image.fromarray(img))\n",
    "\n",
    "    # Create the animation object\n",
    "    ani = animation.FuncAnimation(fig, update, frames=frames, interval=1000 // fps)\n",
    "\n",
    "    # Save the animation as a GIF or video\n",
    "    if save_path is not None:\n",
    "      # Save the animation as a GIF or video\n",
    "      # ani.save(save_path, writer='imagemagick')\n",
    "      for i in range(frames):\n",
    "          update_gif(i)\n",
    "      images[0].save(save_path, save_all=True, append_images=images[1:], duration=1000 // fps, loop=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return ani\n",
    "\n",
    "\n",
    "  if descale:\n",
    "    input = torch.from_numpy(descaling(np.transpose(np.load(f'{pred_paths}/{label}_{id}_input.npy'), (3, 0, 1, 2)).astype('float32')))\n",
    "    target = torch.from_numpy(descaling(np.transpose(np.load(f'{pred_paths}/{label}_{id}_target.npy'), (3, 0, 1, 2)).astype('float32')))\n",
    "  else:\n",
    "    input = torch.from_numpy((np.transpose(np.load(f'{pred_paths}/{label}_{id}_input.npy'), (3, 0, 1, 2)).astype('float32')))\n",
    "    target = torch.from_numpy((np.transpose(np.load(f'{pred_paths}/{label}_{id}_target.npy'), (3, 0, 1, 2)).astype('float32')))\n",
    "  \n",
    "  for simu_path in glob(f\"{pred_paths}/*sim*.npy\"):\n",
    "    save_path  = f\"{pred_paths}/gifs\"\n",
    "    if descale:\n",
    "      save_path += '_descaled'\n",
    "    sim_num = simu_path.split('sim_')[-1].split('.npy')[0]\n",
    "    save_path_full=f\"{save_path}/simu_{sim_num}.gif\"\n",
    "    if not  os.path.exists(save_path_full):\n",
    "      if descale:\n",
    "        simu = torch.from_numpy(descaling(np.transpose(np.load(simu_path), (3, 0, 1, 2)).astype('float32'))) \n",
    "      else:\n",
    "        simu = torch.from_numpy((np.transpose(np.load(simu_path), (3, 0, 1, 2)).astype('float32'))) \n",
    "      os.makedirs(save_path, exist_ok=True)\n",
    "      \n",
    "      vmin=np.min([input.min(),target.min()])\n",
    "      vmax=np.max([input.max(),target.max()])\n",
    "      save_and_plot_v2v(input[0], target[0], simu[0], \n",
    "                        save_path=save_path_full, \n",
    "                        title=f\"Label : {label} , AR : {arnum}, Time : {sample['T']}\", \n",
    "                        fps=3, \n",
    "                        target_channel = None,\n",
    "                        vmin=vmin,\n",
    "                        vmax=vmax\n",
    "                        )\n",
    "      print(f'SIMU {sim_num} : ')\n",
    "      print(input.max(),target.max(),simu.max())\n",
    "      print(input.mean(),target.mean(),simu.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
